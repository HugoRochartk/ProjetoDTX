{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhpLXCyMb48I"
      },
      "source": [
        "Projeto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jdzp66ubAQL",
        "outputId": "d03ef2a3-9d91-4294-de63-286652e888ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting SoccerNet\n",
            "  Downloading SoccerNet-0.1.56-py3-none-any.whl (85 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81.9/85.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from SoccerNet) (4.66.2)\n",
            "Collecting scikit-video (from SoccerNet)\n",
            "  Downloading scikit_video-1.1.11-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from SoccerNet) (3.7.1)\n",
            "Collecting google-measurement-protocol (from SoccerNet)\n",
            "  Downloading google_measurement_protocol-1.1.0-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting pycocoevalcap (from SoccerNet)\n",
            "  Downloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0a0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from google-measurement-protocol->SoccerNet) (2.31.0)\n",
            "Collecting prices>=1.0.0 (from google-measurement-protocol->SoccerNet)\n",
            "  Downloading prices-1.1.1-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->SoccerNet) (2.8.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from pycocoevalcap->SoccerNet) (2.0.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scikit-video->SoccerNet) (1.11.4)\n",
            "Requirement already satisfied: babel>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from prices>=1.0.0->google-measurement-protocol->SoccerNet) (2.14.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->SoccerNet) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (2024.2.2)\n",
            "Installing collected packages: prices, scikit-video, google-measurement-protocol, pycocoevalcap, SoccerNet\n",
            "Successfully installed SoccerNet-0.1.56 google-measurement-protocol-1.1.0 prices-1.1.1 pycocoevalcap-1.2 scikit-video-1.1.11\n"
          ]
        }
      ],
      "source": [
        "#!pip install SoccerNet --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3JtypFYMe24",
        "outputId": "13401c3b-35c3-40e0-890a-c3b226539d90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "HnsJ7bjBMNcF",
        "outputId": "38a3fd28-576e-467f-dd4c-ff4b59830620"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Football-Dataset/england_epl\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\1_224p.mkv...: : 173MiB [00:19, 8.78MiB/s]                         \n",
            "Downloading Football-Dataset/england_epl\\2014-2015\\2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\\2_224p.mkv...: : 180MiB [00:15, 11.8MiB/s]                         \n",
            "Downloading Football-Dataset/england_epl\\2014-2015\\2015-02-21 - 18-00 Crystal Palace 1 - 2 Arsenal\\1_224p.mkv...: : 206MiB [00:17, 11.7MiB/s]                         \n",
            "Downloading Football-Dataset/england_epl\\2014-2015\\2015-02-21 - 18-00 Crystal Palace 1 - 2 Arsenal\\2_224p.mkv...:  79%|███████▊  | 173M/220M [00:08<00:04, 9.44MiB/s] "
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     myDownloader\u001b[38;5;241m.\u001b[39mpassword \u001b[38;5;241m=\u001b[39m password\n\u001b[0;32m     14\u001b[0m     myDownloader\u001b[38;5;241m.\u001b[39mdownloadGames(files\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels-v2.json\u001b[39m\u001b[38;5;124m\"\u001b[39m], split\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 16\u001b[0m unlabeled_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFootball-Dataset/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[1], line 9\u001b[0m, in \u001b[0;36munlabeled_dataset\u001b[1;34m(LocalDirectory)\u001b[0m\n\u001b[0;32m      7\u001b[0m myDownloader \u001b[38;5;241m=\u001b[39m SoccerNetDownloader(LocalDirectory\u001b[38;5;241m=\u001b[39mLocalDirectory)\n\u001b[0;32m      8\u001b[0m myDownloader\u001b[38;5;241m.\u001b[39mpassword \u001b[38;5;241m=\u001b[39m password\n\u001b[1;32m----> 9\u001b[0m myDownloader\u001b[38;5;241m.\u001b[39mdownloadGames(files\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1_224p.mkv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2_224p.mkv\u001b[39m\u001b[38;5;124m\"\u001b[39m], split\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchallenge\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\SoccerNet\\Downloader.py:1021\u001b[0m, in \u001b[0;36mSoccerNetDownloader.downloadGames\u001b[1;34m(self, files, split, task, verbose, randomized)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     gamelist \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(gamelist,\u001b[38;5;28mlen\u001b[39m(gamelist))\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m game \u001b[38;5;129;01min\u001b[39;00m gamelist:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownloadGame(game\u001b[38;5;241m=\u001b[39mgame, files\u001b[38;5;241m=\u001b[39mfiles, spl\u001b[38;5;241m=\u001b[39mspl, verbose\u001b[38;5;241m=\u001b[39mverbose)\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\SoccerNet\\Downloader.py:901\u001b[0m, in \u001b[0;36mSoccerNetDownloader.downloadGame\u001b[1;34m(self, game, files, spl, verbose)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;66;03m# 224p Videos\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1_224p.mkv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2_224p.mkv\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 901\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownloadFile(path_local\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(GameDirectory, file),\n\u001b[0;32m    902\u001b[0m                             path_owncloud\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mOwnCloudServer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_224p\u001b[39m\u001b[38;5;124m\"\u001b[39m, game, file)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m    903\u001b[0m                             user\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMKmZigARdGSoaTT\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# https://exrcsdrive.kaust.edu.sa/exrcsdrive/index.php/s/MKmZigARdGSoaTT # user for video 224p\u001b[39;00m\n\u001b[0;32m    904\u001b[0m                             password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpassword,\n\u001b[0;32m    905\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    907\u001b[0m \u001b[38;5;66;03m# 720p Videos\u001b[39;00m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1_720p.mkv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2_720p.mkv\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\SoccerNet\\Downloader.py:67\u001b[0m, in \u001b[0;36mOwnCloudDownloader.downloadFile\u001b[1;34m(self, path_local, path_owncloud, user, password, verbose)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(path_local), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 67\u001b[0m     urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlretrieve(\n\u001b[0;32m     68\u001b[0m         path_owncloud, path_local, MyProgressBar(path_local))\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m identifier:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mprint\u001b[39m(identifier)\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\urllib\\request.py:270\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    267\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m     block \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(bs)\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\http\\client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Football-Dataset/england_epl\\2014-2015\\2015-02-21 - 18-00 Crystal Palace 1 - 2 Arsenal\\2_224p.mkv...:  79%|███████▉  | 174M/220M [00:24<00:04, 9.44MiB/s]"
          ]
        }
      ],
      "source": [
        "import SoccerNet\n",
        "from SoccerNet.Downloader import SoccerNetDownloader\n",
        "\n",
        "password = \"s0cc3rn3t\"\n",
        "\n",
        "def unlabeled_dataset(LocalDirectory):\n",
        "    myDownloader = SoccerNetDownloader(LocalDirectory=LocalDirectory)\n",
        "    myDownloader.password = password\n",
        "    myDownloader.downloadGames(files=[\"1_224p.mkv\", \"2_224p.mkv\"], split=[\"train\",\"valid\",\"test\",\"challenge\"])\n",
        "\n",
        "def labeled_dataset(LocalDirectory):\n",
        "    myDownloader = SoccerNetDownloader(LocalDirectory=\"Football-Dataset/\")\n",
        "    myDownloader.password = password\n",
        "    myDownloader.downloadGames(files=[\"Labels-v2.json\"], split=[\"train\",\"valid\",\"test\"])\n",
        "\n",
        "#unlabeled_dataset(\"Football-Dataset/\")\n",
        "#labeled_dataset(\"Football-Dataset/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBYzSIJnM0nr",
        "outputId": "617e0477-1adf-4ef7-fcc9-af16cb1bde43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=da0ade5417ae8a280a82929758fa9a867283d7d9b89d3a7c89768315a3f25099\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.2-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.29.2\n"
          ]
        }
      ],
      "source": [
        "#!pip install transformers\n",
        "#!pip install ffmpeg\n",
        "#!pip install torch\n",
        "#!pip install ffmpeg-python\n",
        "#!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4LE5CrQr50Lf"
      },
      "outputs": [],
      "source": [
        "import ffmpeg\n",
        "from pprint import pprint\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJsT1w17hksh",
        "outputId": "414b49ec-044f-42ea-e919-fcb8d5870e4f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_model(model_id):\n",
        "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "\n",
        "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch_dtype, use_safetensors=True\n",
        "                                                      )\n",
        "    model.to(device)\n",
        "\n",
        "    processor = AutoProcessor.from_pretrained(model_id, language=\"en\")\n",
        "\n",
        "    pipe = pipeline(\n",
        "        \"automatic-speech-recognition\",\n",
        "        model=model,\n",
        "        tokenizer=processor.tokenizer,\n",
        "        feature_extractor=processor.feature_extractor,\n",
        "        max_new_tokens=128,\n",
        "        chunk_length_s=30,\n",
        "        batch_size=16,\n",
        "        return_timestamps=True,\n",
        "        torch_dtype=torch_dtype,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    return pipe\n",
        "\n",
        "\n",
        "model_ids = [\"openai/whisper-tiny\", \"openai/whisper-base\", \"openai/whisper-small\", \"openai/whisper-medium\", \"openai/whisper-large\"]\n",
        "#model_id = \"openai/whisper-base\" \n",
        "#pipe = build_model(model_id=model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roiq4-78rulp",
        "outputId": "ad4e9cce-b304-43f4-f216-b982b6f8e425"
      },
      "outputs": [],
      "source": [
        "# environment variables\n",
        "#local_dir = \"drive/MyDrive/DTX/Football-Dataset\"\n",
        "dir = \"Football-Dataset/england_epl/\"\n",
        "\n",
        "def update_txt_file(text, path):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "\n",
        "def audio_to_text(pipe, model_id):\n",
        "  for year in os.listdir(dir):\n",
        "      games = os.path.join(dir, year)\n",
        "      for game in os.listdir(games):\n",
        "          if game != \".ipynb_checkpoints\":\n",
        "              game_dir = os.path.join(games, game)\n",
        "              frag1_dir = os.path.join(game_dir, \"fragments_1_224p\")\n",
        "              frag2_dir = os.path.join(game_dir, \"fragments_2_224p\")\n",
        "\n",
        "              for audioFrag1 in os.listdir(frag1_dir):\n",
        "                result = pipe(frag1_dir + '/' + audioFrag1, return_timestamps=True,  generate_kwargs = {\"language\": \"english\", \"task\": \"translate\"})\n",
        "                update_txt_file(result['text'], frag1_dir + f'/{audioFrag1[:-4]}__{model_id[7:]}.txt')\n",
        "\n",
        "              for audioFrag2 in os.listdir(frag2_dir):\n",
        "                result = pipe(frag2_dir + '/' + audioFrag2, return_timestamps=True,  generate_kwargs = {\"language\": \"english\", \"task\": \"translate\"})\n",
        "                update_txt_file(result['text'], frag2_dir + f'/{audioFrag2[:-4]}__{model_id[7:]}.txt')\n",
        "\n",
        "\n",
        "def clear_nonvideos(path):\n",
        "    for t in os.listdir(path):\n",
        "        if os.path.isdir(path + '/' + t):\n",
        "          shutil.rmtree(path + '/' + t)\n",
        "        else:\n",
        "          if not t.endswith(\".mkv\"):\n",
        "             os.remove(path + '/' + t)\n",
        "\n",
        "\n",
        "def fragment_dataset_audio(audio_cut_length, offset):\n",
        "  for year in os.listdir(dir):\n",
        "      games = os.path.join(dir, year)\n",
        "      for game in os.listdir(games):\n",
        "          game_dir = os.path.join(games, game)\n",
        "\n",
        "          if game != \".ipynb_checkpoints\":\n",
        "            clear_nonvideos(game_dir)\n",
        "            for videoFile in os.listdir(game_dir):\n",
        "                pathVideo = game_dir + \"/\" + videoFile\n",
        "                videoFragments = game_dir + f\"/fragments_{videoFile[:-4]}\"\n",
        "                if not os.path.exists(videoFragments):\n",
        "                  os.mkdir(videoFragments)\n",
        "\n",
        "                duration = float(ffmpeg.probe(pathVideo)[\"format\"][\"duration\"])\n",
        "                steps = duration/audio_cut_length\n",
        "                for n in range(int(steps)+1):\n",
        "                  ffmpeg.input(pathVideo, ss=(n*audio_cut_length)-offset, to=(n+1)*audio_cut_length).output(videoFragments + f\"/fragment_{n}.wav\").run(quiet=True, overwrite_output=True)\n",
        "\n",
        "\n",
        "fragment_dataset_audio(audio_cut_length=30, offset=2)\n",
        "audio_to_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WWa1iVTV6SS6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
            "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m        json\u001b[38;5;241m.\u001b[39mdump(json1,f,indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#nao correr \u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m benchmark()\n",
            "Cell \u001b[1;32mIn[4], line 12\u001b[0m, in \u001b[0;36mbenchmark\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     11\u001b[0m pipe \u001b[38;5;241m=\u001b[39m build_model(model_id\u001b[38;5;241m=\u001b[39mm)\n\u001b[1;32m---> 12\u001b[0m audio_to_text(pipe, m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime (seconds): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[3], line 20\u001b[0m, in \u001b[0;36maudio_to_text\u001b[1;34m(pipe, model_id)\u001b[0m\n\u001b[0;32m     17\u001b[0m frag2_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(game_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfragments_2_224p\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m audioFrag1 \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(frag1_dir):\n\u001b[1;32m---> 20\u001b[0m   result \u001b[38;5;241m=\u001b[39m pipe(frag1_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m audioFrag1, return_timestamps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  generate_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslate\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     21\u001b[0m   update_txt_file(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], frag1_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudioFrag1[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id[\u001b[38;5;241m7\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m audioFrag2 \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(frag2_dir):\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py:285\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    224\u001b[0m     inputs: Union[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    226\u001b[0m ):\n\u001b[0;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m    documentation for more information.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m                `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:1209\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[1;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1210\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1211\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   1212\u001b[0m                 [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1213\u001b[0m             )\n\u001b[0;32m   1214\u001b[0m         )\n\u001b[0;32m   1215\u001b[0m     )\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[1;32m--> 266\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:1123\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1122\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1123\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1124\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py:494\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline._forward\u001b[1;34m(self, model_inputs, return_timestamps, **generate_kwargs)\u001b[0m\n\u001b[0;32m    492\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_features\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 494\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m encoder(inputs, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[0;32m    496\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    497\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs,\n\u001b[0;32m    499\u001b[0m )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;66;03m# whisper longform generation stores timestamps in \"segments\"\u001b[39;00m\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:1212\u001b[0m, in \u001b[0;36mWhisperEncoder.forward\u001b[1;34m(self, input_features, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1204\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1205\u001b[0m             encoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1206\u001b[0m             hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1209\u001b[0m             output_attentions,\n\u001b[0;32m   1210\u001b[0m         )\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1212\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m encoder_layer(\n\u001b[0;32m   1213\u001b[0m             hidden_states,\n\u001b[0;32m   1214\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1215\u001b[0m             layer_head_mask\u001b[38;5;241m=\u001b[39m(head_mask[idx] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1216\u001b[0m             output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1217\u001b[0m         )\n\u001b[0;32m   1219\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:768\u001b[0m, in \u001b[0;36mWhisperEncoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    766\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    767\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn_layer_norm(hidden_states)\n\u001b[1;32m--> 768\u001b[0m hidden_states, attn_weights, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[0;32m    769\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[0;32m    770\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    771\u001b[0m     layer_head_mask\u001b[38;5;241m=\u001b[39mlayer_head_mask,\n\u001b[0;32m    772\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    773\u001b[0m )\n\u001b[0;32m    774\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m    775\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32me:\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:694\u001b[0m, in \u001b[0;36mWhisperSdpaAttention.forward\u001b[1;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    690\u001b[0m query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape(query_states, tgt_len, bsz)\n\u001b[0;32m    692\u001b[0m \u001b[38;5;66;03m# NOTE: SDPA with memory-efficient backend is currently (torch==2.1.2) bugged when using non-contiguous inputs and a custom attn_mask,\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;66;03m# but we are fine here as `_shape` do call `.contiguous()`. Reference: https://github.com/pytorch/pytorch/issues/112577\u001b[39;00m\n\u001b[1;32m--> 694\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mscaled_dot_product_attention(\n\u001b[0;32m    695\u001b[0m     query_states,\n\u001b[0;32m    696\u001b[0m     key_states,\n\u001b[0;32m    697\u001b[0m     value_states,\n\u001b[0;32m    698\u001b[0m     attn_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    699\u001b[0m     dropout_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[0;32m    701\u001b[0m     is_causal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_causal \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    702\u001b[0m )\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m (bsz, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim):\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`attn_output` should be of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(bsz,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\u001b[38;5;250m \u001b[39mtgt_len,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_output\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    708\u001b[0m     )\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "def get_fragment_zero(m):\n",
        "   with open(dir+f\"2014-2015/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley/fragments_1_224p/fragment_0__{m[7:]}.txt\", \"r\") as f:\n",
        "      return f.readline()\n",
        "\n",
        "\n",
        "def benchmark():\n",
        "  for m in model_ids:\n",
        "    fragment_dataset_audio(audio_cut_length=30, offset=2)\n",
        "    start_time = time.time()\n",
        "    pipe = build_model(model_id=m)\n",
        "    audio_to_text(pipe, m)\n",
        "    print(f\"Model: {m}\")\n",
        "    print(f\"Time (seconds): {time.time() - start_time}\")\n",
        "    frag0 = get_fragment_zero(m)\n",
        "    print(f\"Fragment 0: {frag0}\")\n",
        "\n",
        "\n",
        "\n",
        "def benchmark_json():\n",
        "    benchmarks_times = {\"openai/whisper-tiny\": \"7:52\", \"openai/whisper-base\": \"13:34\", \"openai/whisper-small\": \"34:52\", \"openai/whisper-medium\": \"85:36\", \"openai/whisper-large\": \"173:11\"}\n",
        "    benchmarks_frags = {\"openai/whisper-tiny\": \"Maran Koja, the second man, Manaoja, the father of the barley, has also said that in the first part of the league, and in which the second player won the Chelsea 1-3, the third player won the first one, and that he remembered that he was from the last one, and he ended up remontating, but he has to remember without any difficulties. Exactly, I just said that he was going to say, remember that very well, he started winning the barley, Mark Ungol,\",\"openai/whisper-base\": \"Marco Jalduelo manages the ball's penalty. You have to say that they also gave the first game of Liga and in that match he won the Chelsea 1-3. The ball went forward. You have to remember that it went forward and ended up not remembering that much difficult. Exactly, what he was saying, I remember that game, he started the penalty and scored a goal, but the Chelsea won it. That's why he should have problems today, but as he said, football is\", \"openai/whisper-small\": \"Moarran Coya, the duel, the Barley's ball is in control. They also got the first game of the league, and Chelsea won 1-3 in that match. The Barley got ahead of themselves. They had to remember that they got ahead of themselves and ended up getting back on the pitch. They had to remember that Chelsea had too many difficulties. Exactly, that's what I was going to say. I remember that match very well, the Barley started well, scored a goal, but Chelsea won it comfortably.\", \"openai/whisper-medium\": \"The duel has begun, Barley's ball is in the air. They also met in the first game of the league, and in that match Chelsea won 1-3. Barley went ahead. You have to remember that he went ahead in that game and ended up going back without too many difficulties. Exactly, that's what I was going to say. I remember that game very well. Barley started well, scored a goal, but Chelsea won comfortably. That's why today shouldn't have any problems either,\", \"openai/whisper-large\": \"The duel has started, Barley is in control of the ball. It must be said that they also met in the first league match and in that match Chelsea won 1-3. Barley was ahead. We must remember that he was ahead in that match and ended up going back without too many difficulties for Chelsea. Exactly, that's what I was going to say. I remember that match very well. Barley started well, scored a goal, but Chelsea won it comfortably. That's why today he shouldn't have any problems either,\"}\n",
        "  \n",
        "    \n",
        "    json1 = []\n",
        "\n",
        "\n",
        "    for model in benchmarks_times:\n",
        "      dados={\"jogo\": \"2015-02-21 - 18-00 Chelsea 1 - 1 Burnley\", \"model\": model, \"run_time_per_game\": benchmarks_times[model], \"transcricao\": benchmarks_frags[model]}\n",
        "      json1.append(dados)\n",
        "\n",
        "    with open(\"benchmark.txt\", \"w\") as f:\n",
        "       json.dump(json1,f,indent=2)\n",
        "\n",
        "\n",
        "#nao correr \n",
        "#benchmark()\n",
        "\n",
        "#benchmark_json() \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UybxgAfof8B0"
      },
      "outputs": [],
      "source": [
        "# Iterate through folders to apply zero-shot classification\n",
        "classifier = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model=\"facebook/bart-large-mnli\",\n",
        ")\n",
        "\n",
        "#sequence_to_classify = result['text']\n",
        "sequence_to_classify = \" Mark Mitch For the continued work the dry Sun A half minute in and Continue produces work from the top draw to put Liverpool ahead Wow, what a fantastic strike that is Stunning goal Absolutely stunning goal just looking at his technique the goal. I'm just looking at his technique. I mean, it's a umbrella to be slow build up from New York for nobody in the ground for a minute was going to hit him. And there he bends it with power.\"\n",
        "candidate_labels = ['danger moment', 'interesting', 'uninteresting', 'moment without danger']\n",
        "res = classifier(sequence_to_classify, candidate_labels)\n",
        "print(res)\n",
        "\n",
        "# Benchmark the different versions of the model\n",
        "model_versions = [\"facebook/bart-large-mnli\", \"???\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "3XkgxJrIQXqr",
        "outputId": "4fdb4337-0404-49a9-868c-81c29d8d0b0e"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'with' statement on line 28 (<ipython-input-25-9812d90212e9>, line 32)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-9812d90212e9>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    build_labeled_dataset()\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'with' statement on line 28\n"
          ]
        }
      ],
      "source": [
        "# New Dataset Evaluation - Simão e Tiago(trabalha este?)\n",
        "def build_labeled_dataset():\n",
        "    base_path = \"Football-Dataset/england_epl/\"\n",
        "\n",
        "\n",
        "    for year in os.listdir(base_path):\n",
        "        games = os.path.join(base_path, year)\n",
        "        for game in os.listdir(games):\n",
        "            fragments_1 = os.path.join(games, game, \"fragments_1_224p\")\n",
        "            fragments_2 = os.path.join(games, game, \"fragments_2_224p\")\n",
        "\n",
        "            write_fragments(folder=fragments_1, league=\"england_epl\", game=game)\n",
        "            #write_fragments(folder=fragments_2, league=\"england_epl\", game=game)\n",
        "\n",
        "def write_fragments(folder, league, game, audio_cut_length=30, offset=2):\n",
        "\n",
        "    num_transcriptions = len(os.listdir(folder))//2\n",
        "    # ex: (fragment_20.txt, 20)  -> (fragment file name, fragment_number)\n",
        "    fragment_file_names = [(\"fragment_\" + str(i) + f\"__{model_id}.txt\", i) for i in range(num_transcriptions)]\n",
        "\n",
        "\n",
        "    for fragment_file in fragment_file_names:\n",
        "        fragment_path = os.path.join(folder, fragment_file[0])\n",
        "        # These values are counted in seconds\n",
        "        start_time = fragment_file[1] * audio_cut_length - offset\n",
        "        end_time = (fragment_file[1]+1) * audio_cut_length\n",
        "\n",
        "        with open(fragment_path, \"r\") as f:\n",
        "          pass\n",
        "\n",
        "\n",
        "build_labeled_dataset()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vuGKoO05vQd"
      },
      "outputs": [],
      "source": [
        "id;league;game;fragment_start_time;fragment_end_time;label;"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
